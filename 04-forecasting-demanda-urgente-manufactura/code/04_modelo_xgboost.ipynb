{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Modelo XGBoost para Predicci√≥n de Urgencias\n",
    "\n",
    "**Objetivo**: Entrenar clasificador XGBoost para predecir urgencias (Definici√≥n A: P75) usando features de series temporales.\n",
    "\n",
    "## Estrategia:\n",
    "1. Cargar datasets con features (train/test)\n",
    "2. Entrenar XGBoost con class_weight para manejar desbalance\n",
    "3. Evaluar con m√©tricas: Accuracy, Precision, Recall, F1, ROC-AUC\n",
    "4. Analizar feature importance\n",
    "5. Generar predicciones y an√°lisis por producto\n",
    "6. Guardar modelo y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Librer√≠as cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar train/test con features\n",
    "df_train = pd.read_csv('../data/simulated/train_features.csv')\n",
    "df_test = pd.read_csv('../data/simulated/test_features.csv')\n",
    "\n",
    "# Cargar lista de features\n",
    "features_list = pd.read_csv('../data/simulated/feature_list.csv')['feature'].tolist()\n",
    "\n",
    "print(f\"üìä Datos cargados:\")\n",
    "print(f\"\\nTRAIN:\")\n",
    "print(f\"  ‚Ä¢ Registros: {len(df_train):,}\")\n",
    "print(f\"  ‚Ä¢ Productos: {df_train['item_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Urgencias: {df_train['is_urgent_a'].sum():,} ({df_train['is_urgent_a'].mean():.1%})\")\n",
    "\n",
    "print(f\"\\nTEST:\")\n",
    "print(f\"  ‚Ä¢ Registros: {len(df_test):,}\")\n",
    "print(f\"  ‚Ä¢ Productos: {df_test['item_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Urgencias: {df_test['is_urgent_a'].sum():,} ({df_test['is_urgent_a'].mean():.1%})\")\n",
    "\n",
    "print(f\"\\n‚úì Features disponibles: {len(features_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparaci√≥n de Features y Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features y target\n",
    "X_train = df_train[features_list]\n",
    "y_train = df_train['is_urgent_a']\n",
    "\n",
    "X_test = df_test[features_list]\n",
    "y_test = df_test['is_urgent_a']\n",
    "\n",
    "print(f\"‚úì Shapes preparados:\")\n",
    "print(f\"  ‚Ä¢ X_train: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ y_train: {y_train.shape}\")\n",
    "print(f\"  ‚Ä¢ X_test: {X_test.shape}\")\n",
    "print(f\"  ‚Ä¢ y_test: {y_test.shape}\")\n",
    "\n",
    "# Verificar valores infinitos o NaN\n",
    "print(f\"\\nüîç Verificaci√≥n de calidad:\")\n",
    "print(f\"  ‚Ä¢ NaN en X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Inf en X_train: {np.isinf(X_train.values).sum()}\")\n",
    "print(f\"  ‚Ä¢ NaN en X_test: {X_test.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Inf en X_test: {np.isinf(X_test.values).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular scale_pos_weight para manejar desbalance\n",
    "# Ratio de negativos/positivos\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "print(f\"‚öñÔ∏è Class balance:\")\n",
    "print(f\"  ‚Ä¢ Clase 0 (no urgente): {(y_train == 0).sum():,} ({(y_train == 0).mean():.1%})\")\n",
    "print(f\"  ‚Ä¢ Clase 1 (urgente): {(y_train == 1).sum():,} ({(y_train == 1).mean():.1%})\")\n",
    "print(f\"  ‚Ä¢ scale_pos_weight: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar modelo XGBoost\n",
    "print(\"üöÄ Entrenando XGBoost...\\n\")\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=200,           # N√∫mero de √°rboles\n",
    "    max_depth=6,                # Profundidad m√°xima\n",
    "    learning_rate=0.1,          # Tasa de aprendizaje\n",
    "    subsample=0.8,              # Fracci√≥n de muestras por √°rbol\n",
    "    colsample_bytree=0.8,       # Fracci√≥n de features por √°rbol\n",
    "    scale_pos_weight=scale_pos_weight,  # Balance de clases\n",
    "    objective='binary:logistic', # Clasificaci√≥n binaria\n",
    "    eval_metric='logloss',      # M√©trica de evaluaci√≥n\n",
    "    random_state=42,\n",
    "    n_jobs=-1                   # Usar todos los cores\n",
    ")\n",
    "\n",
    "# Entrenar con early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=50  # Mostrar progreso cada 50 iteraciones\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Modelo entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en train y test\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"‚úì Predicciones generadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©tricas en TRAIN\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "\n",
    "# M√©tricas en TEST\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä M√âTRICAS DE EVALUACI√ìN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'M√©trica':<20} {'TRAIN':<15} {'TEST':<15} {'Diferencia':<15}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<20} {train_acc:>14.3f} {test_acc:>14.3f} {train_acc - test_acc:>14.3f}\")\n",
    "print(f\"{'Precision':<20} {train_precision:>14.3f} {test_precision:>14.3f} {train_precision - test_precision:>14.3f}\")\n",
    "print(f\"{'Recall':<20} {train_recall:>14.3f} {test_recall:>14.3f} {train_recall - test_recall:>14.3f}\")\n",
    "print(f\"{'F1-Score':<20} {train_f1:>14.3f} {test_f1:>14.3f} {train_f1 - test_f1:>14.3f}\")\n",
    "print(f\"{'ROC-AUC':<20} {train_auc:>14.3f} {test_auc:>14.3f} {train_auc - test_auc:>14.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interpretaci√≥n\n",
    "print(f\"\\nüéØ INTERPRETACI√ìN:\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {test_acc:.1%} de predicciones correctas\")\n",
    "print(f\"  ‚Ä¢ Precision: {test_precision:.1%} de las urgencias predichas son reales\")\n",
    "print(f\"  ‚Ä¢ Recall: {test_recall:.1%} de las urgencias reales fueron detectadas\")\n",
    "print(f\"  ‚Ä¢ F1-Score: {test_f1:.3f} (balance entre precision y recall)\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC: {test_auc:.3f} (capacidad discriminativa del modelo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report detallado\n",
    "print(\"\\nüìã CLASSIFICATION REPORT (TEST):\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Urgente', 'Urgente']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Urgente', 'Urgente'],\n",
    "            yticklabels=['No Urgente', 'Urgente'],\n",
    "            ax=ax, cbar_kws={'label': 'Frecuencia'})\n",
    "\n",
    "ax.set_xlabel('Predicci√≥n', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Real', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Matriz de Confusi√≥n - XGBoost (Test Set)', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# A√±adir totales\n",
    "total = cm.sum()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "ax.text(2.3, 0.3, f'TN: {tn}\\n({tn/total:.1%})', fontsize=10, ha='left')\n",
    "ax.text(2.3, 1.3, f'TP: {tp}\\n({tp/total:.1%})', fontsize=10, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/confusion_matrix_xgboost.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Gr√°fico guardado: results/confusion_matrix_xgboost.png\")\n",
    "print(f\"\\nDesglose:\")\n",
    "print(f\"  ‚Ä¢ True Negatives (TN): {tn:,} - Correctamente identificados como no urgentes\")\n",
    "print(f\"  ‚Ä¢ False Positives (FP): {fp:,} - Falsa alarma (predijo urgente, no lo era)\")\n",
    "print(f\"  ‚Ä¢ False Negatives (FN): {fn:,} - Urgencia perdida (no detect√≥ urgencia real)\")\n",
    "print(f\"  ‚Ä¢ True Positives (TP): {tp:,} - Urgencia correctamente detectada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Curva ROC\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "        label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# L√≠nea diagonal (clasificador aleatorio)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "        label='Random classifier (AUC = 0.500)')\n",
    "\n",
    "# Punto √≥ptimo (m√°ximo Youden's J)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "ax.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10, \n",
    "        label=f'Optimal threshold = {optimal_threshold:.3f}')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ROC Curve - XGBoost', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/roc_curve_xgboost.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Gr√°fico guardado: results/roc_curve_xgboost.png\")\n",
    "print(f\"\\nUmbral √≥ptimo: {optimal_threshold:.3f}\")\n",
    "print(f\"  ‚Ä¢ TPR (Recall): {tpr[optimal_idx]:.3f}\")\n",
    "print(f\"  ‚Ä¢ FPR: {fpr[optimal_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features_list,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä TOP 20 FEATURES M√ÅS IMPORTANTES:\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in feature_importance.head(20).iterrows():\n",
    "    print(f\"{row['feature']:<30} {row['importance']:>10.4f}\")\n",
    "\n",
    "# Guardar feature importance completa\n",
    "feature_importance.to_csv('../results/feature_importance_xgboost.csv', index=False)\n",
    "print(f\"\\n‚úì Feature importance guardada: results/feature_importance_xgboost.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar top 20 features\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "\n",
    "ax.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Top 20 Features - XGBoost', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/feature_importance_xgboost.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: results/feature_importance_xgboost.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An√°lisis por Producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar predicciones al dataframe de test\n",
    "df_test['pred_urgent'] = y_test_pred\n",
    "df_test['pred_proba'] = y_test_proba\n",
    "\n",
    "# M√©tricas por producto\n",
    "metricas_producto = df_test.groupby('item_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'n_semanas': len(x),\n",
    "        'urgencias_reales': x['is_urgent_a'].sum(),\n",
    "        'urgencias_pred': x['pred_urgent'].sum(),\n",
    "        'accuracy': accuracy_score(x['is_urgent_a'], x['pred_urgent']),\n",
    "        'precision': precision_score(x['is_urgent_a'], x['pred_urgent'], zero_division=0),\n",
    "        'recall': recall_score(x['is_urgent_a'], x['pred_urgent'], zero_division=0),\n",
    "        'f1': f1_score(x['is_urgent_a'], x['pred_urgent'], zero_division=0)\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nüì¶ M√âTRICAS POR PRODUCTO (Estad√≠sticas):\")\n",
    "print(\"=\"*70)\n",
    "print(metricas_producto[['accuracy', 'precision', 'recall', 'f1']].describe())\n",
    "\n",
    "# Top 10 productos mejor predichos (mayor F1)\n",
    "print(\"\\nüèÜ TOP 10 PRODUCTOS MEJOR PREDICHOS (Mayor F1):\")\n",
    "print(\"=\"*70)\n",
    "top_productos = metricas_producto.nlargest(10, 'f1')\n",
    "for idx, row in top_productos.iterrows():\n",
    "    print(f\"{row['item_id']:<20} F1: {row['f1']:.3f}  Accuracy: {row['accuracy']:.3f}  Recall: {row['recall']:.3f}\")\n",
    "\n",
    "# Guardar m√©tricas por producto\n",
    "metricas_producto.to_csv('../results/metricas_por_producto_xgboost.csv', index=False)\n",
    "print(f\"\\n‚úì M√©tricas por producto guardadas: results/metricas_por_producto_xgboost.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# 3. An√°lisis de errores del modelo\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\n\n# 3a. Errores por categor√≠a (si est√° disponible)\nif 'category' in df_test.columns:\n    error_por_categoria = df_test.groupby('category').apply(\n        lambda x: pd.Series({\n            'accuracy': accuracy_score(x['is_urgent_a'], x['pred_urgent']),\n            'n_samples': len(x)\n        })\n    ).reset_index()\n    \n    axes[0, 0].bar(error_por_categoria['category'], error_por_categoria['accuracy'], color='steelblue')\n    axes[0, 0].set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n    axes[0, 0].set_xlabel('Categor√≠a', fontsize=11, fontweight='bold')\n    axes[0, 0].set_title('Accuracy por Categor√≠a de Producto', fontsize=12, fontweight='bold')\n    axes[0, 0].tick_params(axis='x', rotation=45)\n    axes[0, 0].grid(alpha=0.3, axis='y')\n    \n    # A√±adir n√∫mero de muestras encima de barras\n    for idx, row in error_por_categoria.iterrows():\n        axes[0, 0].text(idx, row['accuracy'] + 0.01, f\"n={int(row['n_samples'])}\", \n                       ha='center', fontsize=8)\n\n# 3b. Distribuci√≥n de errores en el tiempo\ndf_test_sorted = df_test.sort_values('week_start')\ndf_test_sorted['error'] = (df_test_sorted['is_urgent_a'] != df_test_sorted['pred_urgent']).astype(int)\nerrores_por_semana = df_test_sorted.groupby('week_start')['error'].mean()\n\naxes[0, 1].plot(errores_por_semana.index, errores_por_semana.values, color='red', linewidth=2)\naxes[0, 1].set_ylabel('Tasa de Error', fontsize=11, fontweight='bold')\naxes[0, 1].set_xlabel('Semana', fontsize=11, fontweight='bold')\naxes[0, 1].set_title('Evoluci√≥n de la Tasa de Error en Test Set', fontsize=12, fontweight='bold')\naxes[0, 1].tick_params(axis='x', rotation=45)\naxes[0, 1].grid(alpha=0.3)\naxes[0, 1].axhline(y=df_test_sorted['error'].mean(), color='orange', \n                   linestyle='--', label=f'Media: {df_test_sorted[\"error\"].mean():.3f}')\naxes[0, 1].legend()\n\n# 3c. An√°lisis de falsos positivos vs falsos negativos\ndf_test['error_type'] = 'Correcto'\ndf_test.loc[(df_test['pred_urgent'] == 1) & (df_test['is_urgent_a'] == 0), 'error_type'] = 'Falso Positivo'\ndf_test.loc[(df_test['pred_urgent'] == 0) & (df_test['is_urgent_a'] == 1), 'error_type'] = 'Falso Negativo'\n\nerror_counts = df_test['error_type'].value_counts()\ncolors_errors = {'Correcto': 'green', 'Falso Positivo': 'orange', 'Falso Negativo': 'red'}\naxes[1, 0].pie(error_counts.values, labels=error_counts.index, autopct='%1.1f%%',\n              colors=[colors_errors.get(x, 'gray') for x in error_counts.index],\n              startangle=90)\naxes[1, 0].set_title('Distribuci√≥n de Tipos de Predicci√≥n', fontsize=12, fontweight='bold')\n\n# 3d. Probabilidades en errores vs aciertos\ncorrectas = df_test[df_test['error_type'] == 'Correcto']['pred_proba']\nfp = df_test[df_test['error_type'] == 'Falso Positivo']['pred_proba']\nfn = df_test[df_test['error_type'] == 'Falso Negativo']['pred_proba']\n\nif len(fp) > 0:\n    axes[1, 1].hist(fp, bins=30, alpha=0.7, label='Falso Positivo', color='orange', edgecolor='black')\nif len(fn) > 0:\n    axes[1, 1].hist(fn, bins=30, alpha=0.7, label='Falso Negativo', color='red', edgecolor='black')\n\naxes[1, 1].axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Umbral')\naxes[1, 1].set_xlabel('Probabilidad Predicha', fontsize=11, fontweight='bold')\naxes[1, 1].set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\naxes[1, 1].set_title('Distribuci√≥n de Probabilidades en Errores', fontsize=12, fontweight='bold')\naxes[1, 1].legend()\naxes[1, 1].grid(alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('../results/analisis_errores_xgboost.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Gr√°fico guardado: results/analisis_errores_xgboost.png\")\nprint(f\"\\\\nüìä Resumen de errores:\")\nprint(f\"  ‚Ä¢ Falsos Positivos: {(df_test['error_type'] == 'Falso Positivo').sum():,} ({(df_test['error_type'] == 'Falso Positivo').mean():.1%})\")\nprint(f\"  ‚Ä¢ Falsos Negativos: {(df_test['error_type'] == 'Falso Negativo').sum():,} ({(df_test['error_type'] == 'Falso Negativo').mean():.1%})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Guardar modelo entrenado (SOBRESCRIBE versi√≥n anterior)\njoblib.dump(model, '../models/xgboost_urgency_classifier.pkl')\nprint(\"‚úì Modelo guardado: models/xgboost_urgency_classifier.pkl\")\n\n# Guardar predicciones de test (SOBRESCRIBE)\npredicciones_test = df_test[['item_id', 'week_start', 'total_sales', \n                              'is_urgent_a', 'pred_urgent', 'pred_proba']].copy()\npredicciones_test.to_csv('../results/predicciones_test_xgboost.csv', index=False)\nprint(\"‚úì Predicciones guardadas: results/predicciones_test_xgboost.csv\")\n\n# Guardar m√©tricas resumen (SOBRESCRIBE)\nmetricas_resumen = pd.DataFrame({\n    'modelo': ['XGBoost'],\n    'train_accuracy': [train_acc],\n    'test_accuracy': [test_acc],\n    'train_precision': [train_precision],\n    'test_precision': [test_precision],\n    'train_recall': [train_recall],\n    'test_recall': [test_recall],\n    'train_f1': [train_f1],\n    'test_f1': [test_f1],\n    'train_auc': [train_auc],\n    'test_auc': [test_auc],\n    'n_features': [len(features_list)],\n    'n_train': [len(df_train)],\n    'n_test': [len(df_test)],\n    'falsos_positivos': [(df_test['error_type'] == 'Falso Positivo').sum()],\n    'falsos_negativos': [(df_test['error_type'] == 'Falso Negativo').sum()]\n})\n\nmetricas_resumen.to_csv('../results/metricas_resumen_xgboost.csv', index=False)\nprint(\"‚úì M√©tricas resumen guardadas: results/metricas_resumen_xgboost.csv\")\n\nprint(\"\\n‚ö†Ô∏è  IMPORTANTE: Todos los archivos anteriores han sido SOBRESCRITOS\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Convertir week_start a datetime si no lo est√°\ndf_test['week_start'] = pd.to_datetime(df_test['week_start'])\n\n# 1. Distribuci√≥n de probabilidades predichas\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# Distribuci√≥n por clase real\nfor clase, label, color in [(0, 'No Urgente', 'skyblue'), (1, 'Urgente', 'salmon')]:\n    probas = df_test[df_test['is_urgent_a'] == clase]['pred_proba']\n    axes[0].hist(probas, bins=50, alpha=0.7, label=label, color=color, edgecolor='black')\n\naxes[0].set_xlabel('Probabilidad Predicha', fontsize=11, fontweight='bold')\naxes[0].set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\naxes[0].set_title('Distribuci√≥n de Probabilidades por Clase Real', fontsize=13, fontweight='bold')\naxes[0].legend()\naxes[0].grid(alpha=0.3)\n\n# Boxplot de probabilidades\ndata_box = [\n    df_test[df_test['is_urgent_a'] == 0]['pred_proba'],\n    df_test[df_test['is_urgent_a'] == 1]['pred_proba']\n]\nbp = axes[1].boxplot(data_box, labels=['No Urgente', 'Urgente'], patch_artist=True)\nbp['boxes'][0].set_facecolor('skyblue')\nbp['boxes'][1].set_facecolor('salmon')\naxes[1].set_ylabel('Probabilidad Predicha', fontsize=11, fontweight='bold')\naxes[1].set_title('Distribuci√≥n de Probabilidades (Boxplot)', fontsize=13, fontweight='bold')\naxes[1].grid(alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('../results/probabilidades_distribucion_xgboost.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Gr√°fico guardado: results/probabilidades_distribucion_xgboost.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "print(\"\\n\" + \"=\"*70)\nprint(\"üéØ RESUMEN MODELO XGBOOST\")\nprint(\"=\"*70)\n\nprint(f\"\\nüìä RENDIMIENTO EN TEST SET:\")\nprint(f\"  ‚Ä¢ Accuracy: {test_acc:.1%}\")\nprint(f\"  ‚Ä¢ Precision: {test_precision:.1%}\")\nprint(f\"  ‚Ä¢ Recall: {test_recall:.1%}\")\nprint(f\"  ‚Ä¢ F1-Score: {test_f1:.3f}\")\nprint(f\"  ‚Ä¢ ROC-AUC: {test_auc:.3f}\")\n\nprint(f\"\\nüîç TOP 5 FEATURES M√ÅS IMPORTANTES:\")\nfor i, (idx, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n    print(f\"  {i}. {row['feature']:<25} (importance: {row['importance']:.4f})\")\n\nprint(f\"\\nüì¶ COBERTURA:\")\nprint(f\"  ‚Ä¢ Productos evaluados: {df_test['item_id'].nunique():,}\")\nprint(f\"  ‚Ä¢ Semanas de predicci√≥n: {df_test['week_start'].nunique()}\")\nprint(f\"  ‚Ä¢ Total predicciones: {len(df_test):,}\")\n\nprint(f\"\\nüíæ ARCHIVOS GENERADOS:\")\nprint(f\"  Modelo:\")\nprint(f\"    ‚Ä¢ models/xgboost_urgency_classifier.pkl\")\nprint(f\"  Visualizaciones:\")\nprint(f\"    ‚Ä¢ results/confusion_matrix_xgboost.png\")\nprint(f\"    ‚Ä¢ results/roc_curve_xgboost.png\")\nprint(f\"    ‚Ä¢ results/feature_importance_xgboost.png\")\nprint(f\"    ‚Ä¢ results/probabilidades_distribucion_xgboost.png\")\nprint(f\"    ‚Ä¢ results/predicciones_series_temporales_xgboost.png\")\nprint(f\"    ‚Ä¢ results/analisis_errores_xgboost.png\")\nprint(f\"  Datos:\")\nprint(f\"    ‚Ä¢ results/feature_importance_xgboost.csv\")\nprint(f\"    ‚Ä¢ results/predicciones_test_xgboost.csv\")\nprint(f\"    ‚Ä¢ results/metricas_por_producto_xgboost.csv\")\nprint(f\"    ‚Ä¢ results/metricas_resumen_xgboost.csv\")\n\nprint(f\"\\n‚úÖ MODELO XGBOOST COMPLETADO\")\nprint(f\"\\n‚ö†Ô∏è  Nota sobre m√©tricas:\")\nif test_acc > 0.95:\n    print(f\"  ‚ö†Ô∏è  ADVERTENCIA: Accuracy muy alta ({test_acc:.1%})\")\n    print(f\"  ‚Üí Revisar si hay data leakage en features de urgencias\")\n    print(f\"  ‚Üí Verificar que rolling features usan shift(1)\")\n    print(f\"  ‚Üí M√©tricas realistas esperadas: 70-85% accuracy\")\nelse:\n    print(f\"  ‚úì M√©tricas en rango realista (sin data leakage aparente)\")\n\nprint(f\"\\nPr√≥ximos pasos:\")\nprint(f\"  ‚Üí Notebook 05: Modelo Prophet (series temporales)\")\nprint(f\"  ‚Üí Notebook 06: Modelo Random Forest\")\nprint(f\"  ‚Üí Notebook 07: Comparaci√≥n de modelos\")\nprint(\"=\"*70)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Modelo y Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo entrenado\n",
    "joblib.dump(model, '../models/xgboost_urgency_classifier.pkl')\n",
    "print(\"‚úì Modelo guardado: models/xgboost_urgency_classifier.pkl\")\n",
    "\n",
    "# Guardar predicciones de test\n",
    "predicciones_test = df_test[['item_id', 'week_start', 'total_sales', \n",
    "                              'is_urgent_a', 'pred_urgent', 'pred_proba']].copy()\n",
    "predicciones_test.to_csv('../results/predicciones_test_xgboost.csv', index=False)\n",
    "print(\"‚úì Predicciones guardadas: results/predicciones_test_xgboost.csv\")\n",
    "\n",
    "# Guardar m√©tricas resumen\n",
    "metricas_resumen = pd.DataFrame({\n",
    "    'modelo': ['XGBoost'],\n",
    "    'train_accuracy': [train_acc],\n",
    "    'test_accuracy': [test_acc],\n",
    "    'train_precision': [train_precision],\n",
    "    'test_precision': [test_precision],\n",
    "    'train_recall': [train_recall],\n",
    "    'test_recall': [test_recall],\n",
    "    'train_f1': [train_f1],\n",
    "    'test_f1': [test_f1],\n",
    "    'train_auc': [train_auc],\n",
    "    'test_auc': [test_auc],\n",
    "    'n_features': [len(features_list)],\n",
    "    'n_train': [len(df_train)],\n",
    "    'n_test': [len(df_test)]\n",
    "})\n",
    "\n",
    "metricas_resumen.to_csv('../results/metricas_resumen_xgboost.csv', index=False)\n",
    "print(\"‚úì M√©tricas resumen guardadas: results/metricas_resumen_xgboost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ RESUMEN MODELO XGBOOST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä RENDIMIENTO EN TEST SET:\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {test_acc:.1%}\")\n",
    "print(f\"  ‚Ä¢ Precision: {test_precision:.1%}\")\n",
    "print(f\"  ‚Ä¢ Recall: {test_recall:.1%}\")\n",
    "print(f\"  ‚Ä¢ F1-Score: {test_f1:.3f}\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC: {test_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nüîç TOP 5 FEATURES M√ÅS IMPORTANTES:\")\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"  {idx+1}. {row['feature']:<25} (importance: {row['importance']:.4f})\")\n",
    "\n",
    "print(f\"\\nüì¶ COBERTURA:\")\n",
    "print(f\"  ‚Ä¢ Productos evaluados: {df_test['item_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Semanas de predicci√≥n: {df_test['week_start'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Total predicciones: {len(df_test):,}\")\n",
    "\n",
    "print(f\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "print(f\"  ‚Ä¢ models/xgboost_urgency_classifier.pkl\")\n",
    "print(f\"  ‚Ä¢ results/confusion_matrix_xgboost.png\")\n",
    "print(f\"  ‚Ä¢ results/roc_curve_xgboost.png\")\n",
    "print(f\"  ‚Ä¢ results/feature_importance_xgboost.png\")\n",
    "print(f\"  ‚Ä¢ results/feature_importance_xgboost.csv\")\n",
    "print(f\"  ‚Ä¢ results/predicciones_test_xgboost.csv\")\n",
    "print(f\"  ‚Ä¢ results/metricas_por_producto_xgboost.csv\")\n",
    "print(f\"  ‚Ä¢ results/metricas_resumen_xgboost.csv\")\n",
    "\n",
    "print(f\"\\n‚úÖ MODELO XGBOOST COMPLETADO\")\n",
    "print(f\"\\nPr√≥ximos pasos:\")\n",
    "print(f\"  ‚Üí Notebook 05: Modelo Prophet (series temporales)\")\n",
    "print(f\"  ‚Üí Notebook 06: Modelo Random Forest\")\n",
    "print(f\"  ‚Üí Notebook 07: Comparaci√≥n de modelos\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}