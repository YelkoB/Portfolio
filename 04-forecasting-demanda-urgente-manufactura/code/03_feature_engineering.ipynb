{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Feature Engineering\n",
    "\n",
    "**Objetivo**: Crear features temporales, de rezago y estad√≠sticas para modelado predictivo de urgencias.\n",
    "\n",
    "## Estrategia:\n",
    "1. Cargar datos de urgencias redefinidas (Definici√≥n A: Percentil 75)\n",
    "2. Filtrar productos con predictibilidad Moderada/Alta\n",
    "3. Crear features:\n",
    "   - **Temporales**: semana, mes, trimestre, estacionalidad\n",
    "   - **Lags**: rezagos de ventas (1, 2, 4, 8, 52 semanas)\n",
    "   - **Rolling stats**: MA, std, min, max en ventanas m√≥viles\n",
    "   - **Urgency-specific**: d√≠as desde √∫ltima urgencia, frecuencia\n",
    "4. Preparar train/test split temporal\n",
    "5. Guardar dataset listo para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Librer√≠as cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar urgencias redefinidas\n",
    "df_urgencias = pd.read_csv('../data/simulated/urgencias_redefinidas.csv')\n",
    "df_urgencias['date'] = pd.to_datetime(df_urgencias['date'])\n",
    "\n",
    "# Cargar clasificaci√≥n de productos\n",
    "df_productos = pd.read_csv('../data/simulated/productos_predecibles.csv')\n",
    "\n",
    "print(f\"Datos cargados:\")\n",
    "print(f\"  ‚Ä¢ Registros totales: {len(df_urgencias):,}\")\n",
    "print(f\"  ‚Ä¢ Productos √∫nicos: {df_urgencias['item_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Rango temporal: {df_urgencias['date'].min()} a {df_urgencias['date'].max()}\")\n",
    "print(f\"\\nDistribuci√≥n de predictibilidad:\")\n",
    "print(df_productos['clasificacion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo productos Predecibles y Moderados\n",
    "productos_modelar = df_productos[\n",
    "    df_productos['clasificacion'].isin(['Predecible', 'Moderado'])\n",
    "]['item_id'].unique()\n",
    "\n",
    "df = df_urgencias[df_urgencias['item_id'].isin(productos_modelar)].copy()\n",
    "df = df.sort_values(['item_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úì Dataset filtrado:\")\n",
    "print(f\"  ‚Ä¢ Productos a modelar: {len(productos_modelar):,}\")\n",
    "print(f\"  ‚Ä¢ Registros: {len(df):,}\")\n",
    "print(f\"  ‚Ä¢ Proporci√≥n urgencias: {df['is_urgent_a'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer componentes temporales\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "# Features c√≠clicas (sin/cos para capturar periodicidad)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['week_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\n",
    "df['week_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52)\n",
    "\n",
    "# Indicadores especiales\n",
    "df['is_q4'] = (df['quarter'] == 4).astype(int)  # Q4 suele tener alta demanda\n",
    "df['is_january'] = (df['month'] == 1).astype(int)  # Enero post-navidad\n",
    "\n",
    "print(\"‚úì Features temporales creadas\")\n",
    "print(f\"  ‚Ä¢ Columnas temporales: {['year', 'month', 'quarter', 'week_of_year', 'month_sin', 'month_cos', 'week_sin', 'week_cos']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lag Features (Rezagos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear lags de ventas por producto\n",
    "lag_periods = [1, 2, 4, 8, 52]  # 1w, 2w, 1m, 2m, 1y\n",
    "\n",
    "for lag in lag_periods:\n",
    "    df[f'sales_lag_{lag}'] = df.groupby('item_id')['total_sales'].shift(lag)\n",
    "    print(f\"  ‚Ä¢ Lag {lag} semanas creado\")\n",
    "\n",
    "# Lags de urgencias (binario)\n",
    "for lag in [1, 2, 4]:\n",
    "    df[f'urgent_lag_{lag}'] = df.groupby('item_id')['is_urgent_a'].shift(lag)\n",
    "\n",
    "print(\"\\n‚úì Lag features creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rolling Statistics (Ventanas M√≥viles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media m√≥vil y estad√≠sticas en ventanas de 4, 8, 12 semanas\n",
    "windows = [4, 8, 12]\n",
    "\n",
    "for window in windows:\n",
    "    # Media m√≥vil\n",
    "    df[f'ma_{window}'] = df.groupby('item_id')['total_sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Desviaci√≥n est√°ndar m√≥vil\n",
    "    df[f'std_{window}'] = df.groupby('item_id')['total_sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "    )\n",
    "    \n",
    "    # M√≠nimo y m√°ximo m√≥vil\n",
    "    df[f'min_{window}'] = df.groupby('item_id')['total_sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).min()\n",
    "    )\n",
    "    \n",
    "    df[f'max_{window}'] = df.groupby('item_id')['total_sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).max()\n",
    "    )\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Rolling stats ventana {window} semanas\")\n",
    "\n",
    "# Features derivadas\n",
    "df['sales_vs_ma4'] = df['total_sales'] / (df['ma_4'] + 1)  # Ratio vs tendencia\n",
    "df['sales_vs_ma12'] = df['total_sales'] / (df['ma_12'] + 1)\n",
    "\n",
    "print(\"\\n‚úì Rolling statistics creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Features Espec√≠ficas de Urgencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_dias_desde_ultima_urgencia(grupo):\n",
    "    \"\"\"Calcula d√≠as desde la √∫ltima urgencia para cada producto\"\"\"\n",
    "    dias = []\n",
    "    ultimo_urgente = None\n",
    "    \n",
    "    for idx, row in grupo.iterrows():\n",
    "        if ultimo_urgente is None:\n",
    "            dias.append(0)\n",
    "        else:\n",
    "            dias.append((row['date'] - ultimo_urgente).days)\n",
    "        \n",
    "        if row['is_urgent_a'] == 1:\n",
    "            ultimo_urgente = row['date']\n",
    "    \n",
    "    return pd.Series(dias, index=grupo.index)\n",
    "\n",
    "# D√≠as desde √∫ltima urgencia\n",
    "df['days_since_urgent'] = df.groupby('item_id').apply(calcular_dias_desde_ultima_urgencia).values\n",
    "\n",
    "# Frecuencia de urgencias en ventanas m√≥viles\n",
    "for window in [4, 8, 12]:\n",
    "    df[f'urgent_freq_{window}w'] = df.groupby('item_id')['is_urgent_a'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).sum()\n",
    "    )\n",
    "    \n",
    "    df[f'urgent_rate_{window}w'] = df[f'urgent_freq_{window}w'] / window\n",
    "\n",
    "print(\"‚úì Features de urgencias creadas\")\n",
    "print(f\"  ‚Ä¢ days_since_urgent: promedio {df['days_since_urgent'].mean():.1f} d√≠as\")\n",
    "print(f\"  ‚Ä¢ urgent_rate_4w: promedio {df['urgent_rate_4w'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Features de Tendencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferencias (cambio respecto a semana anterior)\n",
    "df['sales_diff_1'] = df.groupby('item_id')['total_sales'].diff(1)\n",
    "df['sales_diff_4'] = df.groupby('item_id')['total_sales'].diff(4)\n",
    "\n",
    "# Tasa de crecimiento\n",
    "df['sales_pct_change_1'] = df.groupby('item_id')['total_sales'].pct_change(1)\n",
    "df['sales_pct_change_4'] = df.groupby('item_id')['total_sales'].pct_change(4)\n",
    "\n",
    "# Momentum (diferencia entre MA corta y larga)\n",
    "df['momentum'] = df['ma_4'] - df['ma_12']\n",
    "\n",
    "print(\"‚úì Features de tendencia creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Limpieza y Preparaci√≥n Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar valores faltantes\n",
    "print(\"Missing values por columna:\")\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(missing.head(10))\n",
    "\n",
    "# Rellenar missing values\n",
    "# Para lags: forward fill (usamos el valor anterior)\n",
    "lag_cols = [col for col in df.columns if 'lag_' in col or 'std_' in col]\n",
    "df[lag_cols] = df.groupby('item_id')[lag_cols].fillna(method='ffill')\n",
    "\n",
    "# Para diferencias y pct_change: rellenar con 0\n",
    "diff_cols = [col for col in df.columns if 'diff' in col or 'pct_change' in col]\n",
    "df[diff_cols] = df[diff_cols].fillna(0)\n",
    "\n",
    "# Reemplazar infinitos por NaN y luego rellenar\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(f\"\\n‚úì Missing values manejados\")\n",
    "print(f\"  ‚Ä¢ Nulls restantes: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An√°lisis de Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar features num√©ricas relevantes\n",
    "feature_cols = [col for col in df.columns if col not in [\n",
    "    'item_id', 'date', 'wm_yr_wk', 'total_sales', 'is_urgent_a', 'is_urgent_b', 'is_urgent_c',\n",
    "    'threshold_a', 'ma_4_b', 'threshold_c', 'mean_prod', 'std_prod'\n",
    "]]\n",
    "\n",
    "# Calcular correlaci√≥n con variable objetivo\n",
    "correlations = df[feature_cols + ['is_urgent_a']].corr()['is_urgent_a'].drop('is_urgent_a')\n",
    "correlations = correlations.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nüìä TOP 15 FEATURES M√ÅS CORRELACIONADAS CON URGENCIA:\")\n",
    "print(correlations.head(15))\n",
    "\n",
    "print(\"\\nüìä BOTTOM 10 FEATURES (menor correlaci√≥n):\")\n",
    "print(correlations.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar top correlaciones\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_corr = correlations.head(20)\n",
    "top_corr.plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Correlaci√≥n con is_urgent_a')\n",
    "ax.set_title('Top 20 Features por Correlaci√≥n con Urgencias')\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/feature_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: results/feature_correlations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train/Test Split Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporal: √∫ltimas 26 semanas (6 meses) para test\n",
    "fechas_unicas = sorted(df['date'].unique())\n",
    "fecha_split = fechas_unicas[-26]  # √öltimas 26 semanas para test\n",
    "\n",
    "df_train = df[df['date'] < fecha_split].copy()\n",
    "df_test = df[df['date'] >= fecha_split].copy()\n",
    "\n",
    "print(f\"\\nüìÖ SPLIT TEMPORAL:\")\n",
    "print(f\"\\nTRAIN:\")\n",
    "print(f\"  ‚Ä¢ Fechas: {df_train['date'].min()} a {df_train['date'].max()}\")\n",
    "print(f\"  ‚Ä¢ Semanas: {df_train['date'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Registros: {len(df_train):,}\")\n",
    "print(f\"  ‚Ä¢ Urgencias: {df_train['is_urgent_a'].sum():,} ({df_train['is_urgent_a'].mean():.1%})\")\n",
    "\n",
    "print(f\"\\nTEST:\")\n",
    "print(f\"  ‚Ä¢ Fechas: {df_test['date'].min()} a {df_test['date'].max()}\")\n",
    "print(f\"  ‚Ä¢ Semanas: {df_test['date'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Registros: {len(df_test):,}\")\n",
    "print(f\"  ‚Ä¢ Urgencias: {df_test['is_urgent_a'].sum():,} ({df_test['is_urgent_a'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Datasets Preparados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset completo con features\n",
    "df.to_csv('../data/simulated/dataset_features.csv', index=False)\n",
    "print(f\"‚úì Dataset completo guardado: data/simulated/dataset_features.csv\")\n",
    "print(f\"  ‚Ä¢ Shape: {df.shape}\")\n",
    "\n",
    "# Guardar train/test\n",
    "df_train.to_csv('../data/simulated/train_features.csv', index=False)\n",
    "df_test.to_csv('../data/simulated/test_features.csv', index=False)\n",
    "print(f\"\\n‚úì Train/Test guardados:\")\n",
    "print(f\"  ‚Ä¢ train_features.csv: {df_train.shape}\")\n",
    "print(f\"  ‚Ä¢ test_features.csv: {df_test.shape}\")\n",
    "\n",
    "# Guardar lista de features para modelado\n",
    "features_modeling = [col for col in feature_cols if col in df.columns]\n",
    "pd.DataFrame({'feature': features_modeling}).to_csv('../data/simulated/feature_list.csv', index=False)\n",
    "print(f\"\\n‚úì Lista de features guardada: {len(features_modeling)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESUMEN FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n‚úì Productos procesados: {df['item_id'].nunique():,}\")\n",
    "print(f\"‚úì Registros totales: {len(df):,}\")\n",
    "print(f\"‚úì Features creadas: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nüìÇ ARCHIVOS GENERADOS:\")\n",
    "print(f\"  ‚Ä¢ dataset_features.csv - Dataset completo con todas las features\")\n",
    "print(f\"  ‚Ä¢ train_features.csv - Training set ({len(df_train):,} registros)\")\n",
    "print(f\"  ‚Ä¢ test_features.csv - Test set ({len(df_test):,} registros)\")\n",
    "print(f\"  ‚Ä¢ feature_list.csv - Lista de features para modelado\")\n",
    "print(f\"  ‚Ä¢ feature_correlations.png - Visualizaci√≥n de correlaciones\")\n",
    "\n",
    "print(f\"\\nüéØ CARACTER√çSTICAS DEL DATASET:\")\n",
    "print(f\"  ‚Ä¢ Target: is_urgent_a (Definici√≥n A: Percentil 75)\")\n",
    "print(f\"  ‚Ä¢ Balance: {df['is_urgent_a'].mean():.1%} urgencias\")\n",
    "print(f\"  ‚Ä¢ Horizonte temporal: {df['date'].nunique()} semanas\")\n",
    "print(f\"  ‚Ä¢ Split: {len(df_train)} train / {len(df_test)} test\")\n",
    "\n",
    "print(f\"\\n‚úÖ DATASET LISTO PARA MODELADO\")\n",
    "print(f\"\\nPr√≥ximos pasos:\")\n",
    "print(f\"  ‚Üí Fase 4: Modelado con Prophet\")\n",
    "print(f\"  ‚Üí Fase 5: Modelado con XGBoost\")\n",
    "print(f\"  ‚Üí Fase 6: Modelado con Random Forest\")\n",
    "print(f\"  ‚Üí Fase 7: Comparaci√≥n de modelos\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
